### Introduction

I opted to participate in this competition, and to complete this project, for several reasons.

1) I'm a two-time GSU alum!

2) I've had an interest in NLP for quite some time, both from a linguistics and cognitive science vantage, as well as from an AI/Data Science vantage, but had not had prior opportunities to explore it in depth.

3) There are some Python data-adjacent modules that I'd not experimented with much, having worked principally before this project in R and SAS, with all Python exposure having been limited to more conventional introductory programming tasks. 

4) It's a *project*, and I feel like I learn more readily and enthusiastically when I can connect a new concept to something I'm familiar with, interested in, and can link to a goal.

5) It's a topic I know a good bit about -- I'm something a scribbler myself, for one thing. But my varied background has included philosophy and linguistics, librarianship, public-school education, and the composition of more term- and research-papers than I care to think about. In contrast, other competitions in-progress at the time I began dealt with topics in finance, bioinformatics, and so on. 

In general, on a scale from 'wordsmith' to 'numbers-guy', I've tilted towards the former. My *philosophical* interest in computational lingustics, particularly in terms of writing, cognitive science, and artificial intelligence, considerably predates my technical exposure to the field. Having grown, however, more confident about my skills in math and programming, I felt it would be a natural field to explore further. From a different vantage, I have spent most of my analytical life working in academic (or academia-adjacent) contexts, which are often quite distinct from the scrappy, messy, seat-of-your-pants, trial-by-fire world of data science in journalism, industry, and so on. Things like ensembles and grid search don't make much of an appearance. Thus, I've taken this competition as a means to immerse myself in both NLP and in more rough-'n-ready analytical techniques about which I'd only read, never attempted. 

### Contents

In the sections that follow, I record some of my own analytic thinking as well as summarize some of the content that I learned throughout the process. I've found, over the years, that forcing yourself to consolidate and compose information in a way that can by used by someone else as a teaching/learning resource is one of the most effective ways to confirm your own understanding, iron the content into memory, and sniff-out topics that you 'know' but of which you don't have full conceptual command. I hope that it is found useful, illuminating, and -- yes-- entertaining. 

Part 1: Understanding the Competition
- The Rules, the Rubric.

Part 2: Understanding the Dataset
- Preliminary checks, cleaning, and summary statistics
- Playing with Plotly and TextStats

Part 3: Introductory Methods in Natural Language Processing
- Language Encoding and Cleaning
- Modules
- Whitespace, Lowercase, Punctuation-Erase, HuggingFace* 
- Tokenization, Lemmatization, Stem-atization, De-Stopword-ification

*(Just kidding -- HuggingFace is later. It just rhymed)*

Part 4: Hypothesis Generation and Feature Engineering
- Punctuation Analysis
- Lexical Analysis 
- Stylistic Analysis
- Sentiment Analysis 

Part 5: KDD, Mining, Feature Analysis
- Standardization
- Intra-Feature Correlation
- Dimensionality Reduction
- Feature Selection

Part 6: Exploratory Models
- Sklearn Models with Text
- Sklearn Models with Engineered Features
- XGBoost Model 
- Sklearn FeatureUnion Pipelines + GridSearch
- Features-as-Text Approaches
- Ensembles
- Doc2Vec Approach

Part 7: Neural Networks
- Preliminary Concepts
- Bert + Torch 1
- Bert + Torch 2
- Tensorflow + Distilbert 1
- Tensorflow + Bert
- Tensorflow + Distilbert 2
- LSTM + Keras 1
- Five-Fold DeBerta
- LSTM + Keras 2 

Conclusion

Appendix 1: Some Philosophical Reflections

Appendix 2: Some Frustrations
